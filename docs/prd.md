## Poll.pub — MVP Product Requirements Document (PRD)

---

### 1. Introduction / Overview

“poll.pub” is a web application that collects, stores, and visualises pair‑wise preference data generated by an LLM (and, optionally, validated by real users). The system converts raw answers into a directional weighted graph, enabling researchers, marketers, policy analysts, and hobbyists to see “who prefers what” at a glance—similar to conventional polling, but automated and extensible.

The MVP focuses on one core domain—**country‑relocation desirability**—while laying foundations to add any topic (e.g., brand or IDE preference) later.

---

### 2. Goals

- Capture LLM‑generated answers for unique pairwise questions
- Derive and store a weighted desirability graph for each poll
- Provide clear, shareable insights dashboards with search, filter and drill-down capabilities
- Offer a read‑only REST/JSON API for external data consumers as well as internal usage for charts, etc.
- Keep infrastructure simple and low‑cost

---

### 3. User Stories

* **As the site admin**, I want to create a new poll in Django Admin so that an LLM can generate responses automatically.
* **As a research / data analyst**, I want to download raw pairwise data via the API so I can run my own statistical models.
* **As a marketer**, I want to view a ranked list of desirable countries for a given demographic to inform campaign targeting.
* **As a hobbyist**, I want to explore an interactive network graph to discover unexpected preference patterns.

---

### 4. Functional Requirements

1. **Poll Management**
   1.1 The system shall allow admins (staff users) to create/edit polls in Django Admin, specifying: topic, demographic prompt template, LLM model/version, number of samples per pair, and batching parameters.
   1.2 The system shall generate all unique unordered pairs for the poll’s option list and persist them as “questions”.

2. **LLM Answer Ingestion**
   2.1 The system shall accept CSV import of LLM answers, containing: question ID, chosen option, confidence score (0‑1).
   2.2 The system shall validate imports (e.g., orphan question IDs, missing fields) and reject invalid rows.
   2.3 The system shall support batched prompt execution to minimise LLM API cost.

3. **Data Derivation & Caching**
   3.1 After import, the system shall compute a directional weighted edge for each ordered pair (A → B) with weight = (# times A preferred over B) / (total answers for A vs B).
   3.2 The system shall persist graph data in a dedicated **GraphEdge** table keyed by poll ID.
   3.3 The system shall store per‑option aggregate desirability scores (e.g., PageRank, win‑rate) in an **AggregateStats** table.
   3.4 Graph edges and aggregates shall be recomputed and overwritten after each successful import, ensuring queries hit pre‑materialised tables rather than recalculating on the fly.

4. **Insights Dashboard (Web UI)**
   4.1 The system shall provide a poll overview page showing: summary stats, top‑5 most desired options, and a heat‑map matrix (Chart.js).
   4.2 The system shall render an interactive network graph (Sigma.js) where node size reflects global desirability and edge thickness reflects preference strength.
   4.3 All visual components shall update automatically when new data is imported.
   4.4 UI shall use Bootstrap 5 and support desktop and tablet resolutions (≥ 768 px).

5. **Read‑Only API (django‑ninja)**
   5.1 `/api/polls/` **GET** → list polls (id, title, created, status).
   5.2 `/api/polls/{id}/pairs/` **GET** → raw pairwise answers (paginated).
   5.3 `/api/polls/{id}/graph/` **GET** → nodes & edges JSON.
   5.4 `/api/polls/{id}/stats/` **GET** → pre‑computed aggregates (top rankings, win rates, confidence intervals).
   5.5 API shall be read‑only; no authentication in v1.

6. **Confidence Handling & Validation**
   6.1 Each answer record shall store a `confidence` field.
   6.2 Dashboard shall surface average confidence and flag pairs with median confidence < 0.5.

---

### 5. Non‑Goals / Out of Scope (v1)

* End‑user account creation, login, or multi‑tenant separation
* Direct integration that triggers the LLM automatically (import remains manual)
* Human voting UI
* Advanced statistical modelling (e.g., Bradley‑Terry) beyond simple win‑rates/PageRank
* **CSV export endpoint** (nice‑to‑have for later)

---

### 6. Design Considerations

* **Look & Feel:** Clean Bootstrap 5 styles, light theme, minimal chrome.
* **Visualisation Libraries:** Chart.js for matrices/line charts; Sigma.js for graph networks (fallback D3 if needed).
* **Navigation:** Left sidebar listing polls → selecting a poll loads dashboard.
* **Accessibility:** Use contrasting colours; keyboard‑navigable charts where feasible.

---

### 7. Technical Considerations

* **Stack:** Django 5.x, django‑ninja, Bootstrap 5, SQLite (default).
* **Hosting:** Single AWS EC2 (t3a.small) behind Nginx; static assets on S3.
* **Task Runner:** Management command (`manage.py import_answers <file>`) handles batched prompt execution and answer ingestion; future‑proof to plug into Celery/RQ.
* **Graph Caching:** After each import, recompute graphs & aggregates and save to tables; API and dashboard read only from these tables for fast response.
* **Schema Sketch:**

  ```
  Poll ─┬── Option
        ├── QuestionPair
        ├── Answer (confidence, chosen_option_id)
        ├── GraphEdge (from_option, to_option, weight)
        └── AggregateStats (win_rate, pagerank, etc.)
  ```
* **LLM Cost Optimisation:** Batch prompts wherever possible; expose `batch_size` on poll definition.
* **Versioning:** Store LLM model name, temperature and batch size per poll for reproducibility.
* **Testing:** Unit tests for import parser, graph computation; snapshot tests for API responses.

---
